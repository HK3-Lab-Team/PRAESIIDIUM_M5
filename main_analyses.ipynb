{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This notebook contains the code for the Shanghai T2DM data analysis, as described in Section 4 and 5 of M5 (WP3) \"EXplainable ML Model development\" by HK3Lab:\n",
    "\n",
    "    - Observing and explaining time-dependent relationships between clinical variables and daily CGM time series (Section 4)\n",
    "    - LLM-driven food categorization for CGM event analysis (Section 5)\n",
    "\n",
    "    Running the analyses assumes you have already installed all requiredments in `./requirements.txt` and downloaded the data in the `./data` folder (see README.md for instructions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVING AND EXPLAINING TIME-DEPENDENT RELATIONSHIPS BETWEEN CLINICAL VARIABLES AND DAILY CGM TIME SERIES (Section 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_preprocess.cgm_data_class import ChineseCGMData\n",
    "from typing import Optional\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_base_path = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data by instantiating the ChineseCGMData class. \n",
    "When calling this class, we can expect the dtype of some columns to be difficult to infer. Python will fall back to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_data = ChineseCGMData(local_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects are string IDs, e.g.,\n",
    "random_id = chinese_data.get_random_subject_id()\n",
    "random_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each subject has these columns\n",
    "chinese_data.df_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects are stored in a dataframe\n",
    "chinese_data.df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_columns = [\"Patient Number\",\"Gender (Female=1, Male=2)\",\"Age (years)\",\"Height (m)\",\"Weight (kg)\",\"BMI (kg/m2)\"]\n",
    "patients_demographics = chinese_data.df_metadata.select(pl.col(demographics_columns)).unique()\n",
    "patients_demographics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for visualization and statistical testing\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below serves to\n",
    "- visualize the distribution of numeric metadata variables from the Shanghai T2DM dataset using histograms with kernel density estimates;\n",
    "- compute and display a correlation heatmap to highlight relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_numeric_distributions(chinese_data=ChineseCGMData) -> None:\n",
    "    \"\"\"\n",
    "    Create a subplot grid of histograms with kernel density estimates \n",
    "    for all numeric columns in the metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get numeric columns\n",
    "    numeric_cols = [\n",
    "        \"Fasting Plasma Glucose (mg/dl)\",\n",
    "        \"2-hour Postprandial Plasma Glucose (mg/dl)\",\n",
    "        \"Fasting C-peptide (nmol/L)\",\n",
    "        \"2-hour Postprandial C-peptide (nmol/L)\",\n",
    "        \"Fasting Insulin (pmol/L)\",\n",
    "        \"2-hour Postprandial insulin (pmol/L)\",\n",
    "        \"HbA1c (mmol/mol)\",\n",
    "        \"Glycated Albumin (%)\",\n",
    "        \"Total Cholesterol (mmol/L)\",\n",
    "        \"Triglyceride (mmol/L)\",\n",
    "        \"High-Density Lipoprotein Cholesterol (mmol/L)\",\n",
    "        \"Low-Density Lipoprotein Cholesterol (mmol/L)\",\n",
    "        \"Creatinine (umol/L)\",\n",
    "        \"Estimated Glomerular Filtration Rate (ml/min/1.73m2)\",\n",
    "        \"Uric Acid (mmol/L)\",\n",
    "        \"Blood Urea Nitrogen (mmol/L)\",\n",
    "        \"Age (years)\",\n",
    "        \"Height (m)\",\n",
    "        \"Weight (kg)\",\n",
    "        \"BMI (kg/m2)\",\n",
    "    ]\n",
    "    \n",
    "    # Filter existing columns\n",
    "    numeric_cols = [col for col in numeric_cols if col in chinese_data.df_metadata.columns]\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    fig.suptitle('Distribution of Numeric Variables in Metadata', y=1.02, fontsize=16)\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for idx, (ax, col) in enumerate(zip(axes_flat, numeric_cols)):\n",
    "        # Get data without nulls\n",
    "        data = chinese_data.df_metadata[col].drop_nulls().to_numpy()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            # Calculate basic statistics\n",
    "            mean_val = np.mean(data)\n",
    "            median_val = np.median(data)\n",
    "            std_val = np.std(data)\n",
    "            \n",
    "            # Create histogram\n",
    "            counts, bins, _ = ax.hist(data, bins='auto', density=True, \n",
    "                                    alpha=0.6, color='skyblue')\n",
    "            \n",
    "            # Kernel density estimation\n",
    "            kde_x = np.linspace(min(data), max(data), 200)\n",
    "            kde = stats.gaussian_kde(data)\n",
    "            ax.plot(kde_x, kde(kde_x), 'r-', lw=2, label='KDE')\n",
    "            \n",
    "            # Add vertical lines for mean and median\n",
    "            ax.axvline(mean_val, color='red', linestyle='--', alpha=0.5, \n",
    "                      label=f'Mean: {mean_val:.1f}')\n",
    "            ax.axvline(median_val, color='green', linestyle='--', alpha=0.5,\n",
    "                      label=f'Median: {median_val:.1f}')\n",
    "            \n",
    "            # Calculate missing value percentage\n",
    "            missing_pct = (chinese_data.df_metadata[col].null_count() / \n",
    "                         len(chinese_data.df_metadata)) * 100\n",
    "            \n",
    "            # Add title with stats\n",
    "            ax.set_title(f'{col}\\n'\n",
    "                        f'(n={len(data)}, {missing_pct:.1f}% missing)\\n'\n",
    "                        f'std: {std_val:.1f}', \n",
    "                        fontsize=10)\n",
    "            \n",
    "            # Add legend\n",
    "            ax.legend(fontsize='small')\n",
    "            \n",
    "            # Rotate x-axis labels if needed\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'No valid data for {col}', \n",
    "                   ha='center', va='center')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(numeric_cols), len(axes_flat)):\n",
    "        fig.delaxes(axes_flat[idx])\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    stats_df = (chinese_data.df_metadata\n",
    "                .select(numeric_cols)\n",
    "                .describe()\n",
    "                .with_columns(pl.col(\"*\").cast(pl.Float64, strict=False)))\n",
    "    \n",
    "    print(stats_df)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Calculate correlations using correct Polars syntax\n",
    "    corr_values = np.zeros((len(numeric_cols), len(numeric_cols)))\n",
    "    for i, col1 in enumerate(numeric_cols):\n",
    "        for j, col2 in enumerate(numeric_cols):\n",
    "            # Calculate correlation using pl.corr correctly\n",
    "            corr = (\n",
    "                chinese_data.df_metadata\n",
    "                .select(pl.corr(col1, col2))\n",
    "                .item()\n",
    "            )\n",
    "            corr_values[i, j] = round(float(corr), 2) if corr is not None else np.nan\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_values), k=1)  # Mask upper triangle\n",
    "    sns.heatmap(corr_values,\n",
    "                annot=True,\n",
    "                cmap='RdBu_r',\n",
    "                center=0,\n",
    "                fmt='.2f',\n",
    "                xticklabels=numeric_cols,\n",
    "                yticklabels=numeric_cols,\n",
    "                mask=mask)  # Apply mask to show only lower triangle\n",
    "    plt.title('Correlation Matrix of Numeric Variables')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_numeric_distributions(chinese_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_data.df_metadata[\"2-hour Postprandial Plasma Glucose (mg/dl)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = chinese_data.get_cgm_data_at_resolution(resolution=\"3h\")\n",
    "daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_significance_metrics(hourly_stats: list[dict]) -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Calculate number of significant hours and their ratio.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (number of significant hours, ratio of significant hours)\n",
    "    \"\"\"\n",
    "    significant_hours = sum(1 for stat in hourly_stats if stat['p_value'] < 0.05)\n",
    "    ratio = significant_hours / 24\n",
    "    return significant_hours, ratio\n",
    "\n",
    "\n",
    "def visualize_cgm_patterns_by_group(\n",
    "    chinese_data: ChineseCGMData,\n",
    "    group1_filter: pl.Expr,\n",
    "    group2_filter: Optional[pl.Expr] = None,\n",
    "    show_individual: bool = False,\n",
    "    group_names: tuple[str, str] = (\"Group 1\", \"Group 2\"),\n",
    "    display: bool = True,\n",
    "    title: str = 'Daily CGM Patterns by Group with Hourly Statistical Comparison'\n",
    ") -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    \"\"\"\n",
    "    Visualize daily CGM patterns comparing two groups defined by metadata filters.\n",
    "    Includes hourly statistical comparisons between groups.\n",
    "    \n",
    "    Args:\n",
    "        chinese_data: ChineseCGMData object containing the data\n",
    "        group1_filter: Polars expression to filter metadata for group 1\n",
    "        group2_filter: Polars expression to filter metadata for group 2 (if None, uses NOT group1_filter)\n",
    "        show_individual: If True, shows individual subject curves\n",
    "        group_names: Names for the two groups in the legend\n",
    "        display: Whether to display the plot immediately\n",
    "        title: Title for the plot\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (figure, list of axes)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get daily data\n",
    "    cgm_resolution_df = chinese_data.get_cgm_data_at_resolution(\"1d\")\n",
    "    \n",
    "    # Filter patients based on metadata\n",
    "    group1_patients = chinese_data.df_metadata.filter(group1_filter)[\"Patient Number\"].to_list()\n",
    "    if group2_filter is None:\n",
    "        group2_patients = chinese_data.df_metadata.filter(~group1_filter)[\"Patient Number\"].to_list()\n",
    "    else:\n",
    "        group2_patients = chinese_data.df_metadata.filter(group2_filter)[\"Patient Number\"].to_list()\n",
    "    \n",
    "    def process_patient_data(patient_df):\n",
    "        \"\"\"Process individual patient data into hourly bins\"\"\"\n",
    "        daily_data = {hour: [] for hour in range(24)}\n",
    "        \n",
    "        for row in patient_df.iter_rows(named=True):\n",
    "            for time, value in zip(row[\"cgm_time_stamp\"], row[\"CGM\"]):\n",
    "                hour = time.hour\n",
    "                daily_data[hour].append(value)\n",
    "        \n",
    "        # Calculate mean for each hour\n",
    "        hourly_means = []\n",
    "        for hour in range(24):\n",
    "            if daily_data[hour]:\n",
    "                hourly_means.append(np.mean(daily_data[hour]))\n",
    "            else:\n",
    "                hourly_means.append(np.nan)\n",
    "                \n",
    "        return hourly_means\n",
    "    \n",
    "    # Process each group\n",
    "    group1_curves = {}\n",
    "    group2_curves = {}\n",
    "    \n",
    "    for patient in group1_patients:\n",
    "        patient_df = cgm_resolution_df.filter(pl.col(\"Patient Number\") == patient)\n",
    "        group1_curves[patient] = process_patient_data(patient_df)\n",
    "    \n",
    "    for patient in group2_patients:\n",
    "        patient_df = cgm_resolution_df.filter(pl.col(\"Patient Number\") == patient)\n",
    "        group2_curves[patient] = process_patient_data(patient_df)\n",
    "    \n",
    "    # Convert to arrays for easier statistical analysis\n",
    "    hours = np.arange(24)\n",
    "    group1_array = np.array(list(group1_curves.values()))\n",
    "    group2_array = np.array(list(group2_curves.values()))\n",
    "    \n",
    "    # Calculate hourly statistics and t-tests\n",
    "    hourly_stats = []\n",
    "    for hour in range(24):\n",
    "        g1_hour = group1_array[:, hour]\n",
    "        g2_hour = group2_array[:, hour]\n",
    "        \n",
    "        # Remove NaN values for t-test\n",
    "        g1_clean = g1_hour[~np.isnan(g1_hour)]\n",
    "        g2_clean = g2_hour[~np.isnan(g2_hour)]\n",
    "        \n",
    "        if len(g1_clean) > 0 and len(g2_clean) > 0:\n",
    "            t_stat, p_val = stats.ttest_ind(g1_clean, g2_clean)\n",
    "        else:\n",
    "            t_stat, p_val = np.nan, np.nan\n",
    "            \n",
    "        hourly_stats.append({\n",
    "            'hour': hour,\n",
    "            'g1_mean': np.nanmean(g1_hour),\n",
    "            'g1_std': np.nanstd(g1_hour),\n",
    "            'g2_mean': np.nanmean(g2_hour),\n",
    "            'g2_std': np.nanstd(g2_hour),\n",
    "            'p_value': p_val\n",
    "        })\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), height_ratios=[3, 1])\n",
    "    \n",
    "    # Plot CGM patterns\n",
    "    if show_individual:\n",
    "        # Plot individual curves for both groups\n",
    "        for curves, color in [(group1_curves, 'blue'), (group2_curves, 'red')]:\n",
    "            for patient_data in curves.values():\n",
    "                ax1.plot(hours, patient_data, alpha=0.3, color=color, linewidth=1)\n",
    "        \n",
    "        # Add representative lines for legend\n",
    "        ax1.plot([], [], color='blue', alpha=0.8, label=f'{group_names[0]} (n={len(group1_curves)})')\n",
    "        ax1.plot([], [], color='red', alpha=0.8, label=f'{group_names[1]} (n={len(group2_curves)})')\n",
    "    \n",
    "    # Always show means\n",
    "    g1_mean = np.nanmean(group1_array, axis=0)\n",
    "    g1_sem = np.nanstd(group1_array, axis=0) / np.sqrt(len(group1_curves))\n",
    "    g2_mean = np.nanmean(group2_array, axis=0)\n",
    "    g2_sem = np.nanstd(group2_array, axis=0) / np.sqrt(len(group2_curves))\n",
    "    \n",
    "    ax1.plot(hours, g1_mean, color='blue', linewidth=2, \n",
    "             label=f'{group_names[0]} Mean' if show_individual else f'{group_names[0]} (n={len(group1_curves)})')\n",
    "    ax1.fill_between(hours, g1_mean - 1.96*g1_sem, g1_mean + 1.96*g1_sem, color='blue', alpha=0.2)\n",
    "    \n",
    "    ax1.plot(hours, g2_mean, color='red', linewidth=2,\n",
    "             label=f'{group_names[1]} Mean' if show_individual else f'{group_names[1]} (n={len(group2_curves)})')\n",
    "    ax1.fill_between(hours, g2_mean - 1.96*g2_sem, g2_mean + 1.96*g2_sem, color='red', alpha=0.2)\n",
    "    \n",
    "    # Plot p-values (1 - p_value for better visualization)\n",
    "    p_values = [stat['p_value'] for stat in hourly_stats]\n",
    "    significance = [1 - p for p in p_values]  # Transform to show significance\n",
    "    ax2.plot(hours, significance, 'k-', linewidth=2)\n",
    "    ax2.axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='p=0.05')\n",
    "    ax2.fill_between(hours, 0, significance, alpha=0.2)\n",
    "    \n",
    "    # Set p-value plot styling\n",
    "    ax2.set_xlabel('Hour of Day')\n",
    "    ax2.set_ylabel('Statistical Significance (1-p)')\n",
    "    ax2.set_ylim(0.8, 1)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Customize plots\n",
    "    ax1.set_xlabel('Hour of Day')\n",
    "    ax1.set_ylabel('CGM Value (mg/dL)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add meal time indicators\n",
    "    meal_times = [(6, 'Breakfast'), (12, 'Lunch'), (18, 'Dinner')]\n",
    "    for hour, meal in meal_times:\n",
    "        ax1.axvline(x=hour, color='gray', linestyle='--', alpha=0.3)\n",
    "        # Place text at bottom of plot instead of top\n",
    "        ax1.text(hour, ax1.get_ylim()[0], meal, \n",
    "                rotation=90, va='top', ha='right')\n",
    "    \n",
    "    ax2.set_xlabel('Hour of Day')\n",
    "    ax2.set_ylabel('-log10(p-value)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Calculate significance metrics\n",
    "    significant_hours, ratio = calculate_significance_metrics(hourly_stats)\n",
    "    \n",
    "    # Update title to include significance ratio\n",
    "    plt.suptitle(f\"{title}\\nSignificant hours: {significant_hours}/24 ({ratio:.2%})\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if display:\n",
    "        plt.show()\n",
    "        # Print key statistics\n",
    "        print(\"\\nGroup Statistics:\")\n",
    "        print(f\"{group_names[0]}: {len(group1_curves)} subjects\")\n",
    "        print(f\"{group_names[1]}: {len(group2_curves)} subjects\")\n",
    "        \n",
    "        print(\"\\nSignificant Differences (p < 0.05):\")\n",
    "        for stat in hourly_stats:\n",
    "            if stat['p_value'] < 0.05:\n",
    "                print(f\"Hour {stat['hour']:02d}:00 - \"\n",
    "                      f\"Group 1: {stat['g1_mean']:.1f}±{stat['g1_std']:.1f}, \"\n",
    "                      f\"Group 2: {stat['g2_mean']:.1f}±{stat['g2_std']:.1f}, \"\n",
    "                      f\"p={stat['p_value']:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return fig, [ax1, ax2], significant_hours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cgm_statistics(\n",
    "    chinese_data: ChineseCGMData,\n",
    "    group1_filter: pl.Expr,\n",
    "    group2_filter: Optional[pl.Expr] = None,\n",
    ") -> tuple[dict[str, list[dict]], int]:\n",
    "    \"\"\"\n",
    "    Calculate hourly statistics between two groups.\n",
    "    Returns hourly statistics and number of significant hours.\n",
    "    \"\"\"\n",
    "    # Get daily data\n",
    "    cgm_resolution_df = chinese_data.get_cgm_data_at_resolution(\"1d\")\n",
    "    \n",
    "    # Filter patients based on metadata\n",
    "    group1_patients = chinese_data.df_metadata.filter(group1_filter)[\"Patient Number\"].to_list()\n",
    "    if group2_filter is None:\n",
    "        group2_patients = chinese_data.df_metadata.filter(~group1_filter)[\"Patient Number\"].to_list()\n",
    "    else:\n",
    "        group2_patients = chinese_data.df_metadata.filter(group2_filter)[\"Patient Number\"].to_list()\n",
    "    \n",
    "    def process_patient_data(patient_df):\n",
    "        daily_data = {hour: [] for hour in range(24)}\n",
    "        for row in patient_df.iter_rows(named=True):\n",
    "            for time, value in zip(row[\"cgm_time_stamp\"], row[\"CGM\"]):\n",
    "                hour = time.hour\n",
    "                daily_data[hour].append(value)\n",
    "                \n",
    "        hourly_means = []\n",
    "        for hour in range(24):\n",
    "            if daily_data[hour]:\n",
    "                hourly_means.append(np.mean(daily_data[hour]))\n",
    "            else:\n",
    "                hourly_means.append(np.nan)\n",
    "        return hourly_means\n",
    "    \n",
    "    # Process each group\n",
    "    group1_curves = {}\n",
    "    group2_curves = {}\n",
    "    \n",
    "    for patient in group1_patients:\n",
    "        patient_df = cgm_resolution_df.filter(pl.col(\"Patient Number\") == patient)\n",
    "        group1_curves[patient] = process_patient_data(patient_df)\n",
    "    \n",
    "    for patient in group2_patients:\n",
    "        patient_df = cgm_resolution_df.filter(pl.col(\"Patient Number\") == patient)\n",
    "        group2_curves[patient] = process_patient_data(patient_df)\n",
    "    \n",
    "    # Convert to arrays for statistics\n",
    "    group1_array = np.array(list(group1_curves.values()))\n",
    "    group2_array = np.array(list(group2_curves.values()))\n",
    "    \n",
    "    # Calculate hourly statistics and t-tests\n",
    "    hourly_stats = []\n",
    "    for hour in range(24):\n",
    "        g1_hour = group1_array[:, hour]\n",
    "        g2_hour = group2_array[:, hour]\n",
    "        \n",
    "        # Remove NaN values for t-test\n",
    "        g1_clean = g1_hour[~np.isnan(g1_hour)]\n",
    "        g2_clean = g2_hour[~np.isnan(g2_hour)]\n",
    "        \n",
    "        if len(g1_clean) > 0 and len(g2_clean) > 0:\n",
    "            t_stat, p_val = stats.ttest_ind(g1_clean, g2_clean)\n",
    "        else:\n",
    "            t_stat, p_val = np.nan, np.nan\n",
    "            \n",
    "        hourly_stats.append({\n",
    "            'hour': hour,\n",
    "            'g1_mean': np.nanmean(g1_hour),\n",
    "            'g1_std': np.nanstd(g1_hour),\n",
    "            'g2_mean': np.nanmean(g2_hour),\n",
    "            'g2_std': np.nanstd(g2_hour),\n",
    "            'p_value': p_val\n",
    "        })\n",
    "    \n",
    "    significant_hours = sum(1 for stat in hourly_stats if stat['p_value'] < 0.05)\n",
    "    \n",
    "    return {\n",
    "        'hourly_stats': hourly_stats,\n",
    "        'group1_curves': group1_curves,\n",
    "        'group2_curves': group2_curves,\n",
    "        'group_sizes': (len(group1_curves), len(group2_curves))\n",
    "    }, significant_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cgm_patterns_by_medians(\n",
    "    chinese_data: ChineseCGMData,\n",
    "    show_individual: bool = False,\n",
    "    excluded_vars: list[str] = None\n",
    ") -> tuple[list[str], dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Create subplots of CGM patterns for each numeric variable, splitting subjects \n",
    "    by the median value of each variable. Plots are sorted by statistical significance.\n",
    "    \n",
    "    Args:\n",
    "        chinese_data: ChineseCGMData object containing the data\n",
    "        show_individual: If True, shows individual subject curves\n",
    "        excluded_vars: List of numeric variables to exclude from analysis\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (list of variables ordered by significance, dictionary of significance counts)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define numeric columns\n",
    "    numeric_cols = [\n",
    "        \"Fasting Plasma Glucose (mg/dl)\",\n",
    "        \"2-hour Postprandial Plasma Glucose (mg/dl)\",\n",
    "        \"Fasting C-peptide (nmol/L)\",\n",
    "        \"2-hour Postprandial C-peptide (nmol/L)\",\n",
    "        \"Fasting Insulin (pmol/L)\",\n",
    "        \"2-hour Postprandial insulin (pmol/L)\",\n",
    "        \"HbA1c (mmol/mol)\",\n",
    "        \"Glycated Albumin (%)\",\n",
    "        \"Total Cholesterol (mmol/L)\",\n",
    "        \"Triglyceride (mmol/L)\",\n",
    "        \"High-Density Lipoprotein Cholesterol (mmol/L)\",\n",
    "        \"Low-Density Lipoprotein Cholesterol (mmol/L)\",\n",
    "        \"Creatinine (umol/L)\",\n",
    "        \"Estimated Glomerular Filtration Rate (ml/min/1.73m2)\",\n",
    "        \"Uric Acid (mmol/L)\",\n",
    "        \"Blood Urea Nitrogen (mmol/L)\",\n",
    "        \"Age (years)\",\n",
    "        \"Height (m)\",\n",
    "        \"Weight (kg)\",\n",
    "        \"BMI (kg/m2)\",\n",
    "    ]\n",
    "    \n",
    "    # Remove excluded variables\n",
    "    if excluded_vars:\n",
    "        numeric_cols = [col for col in numeric_cols if col not in excluded_vars]\n",
    "    \n",
    "    # Filter to only existing columns with non-null values\n",
    "    valid_cols = []\n",
    "    for col in numeric_cols:\n",
    "        if col in chinese_data.df_metadata.columns:\n",
    "            if chinese_data.df_metadata[col].null_count() < len(chinese_data.df_metadata):\n",
    "                valid_cols.append(col)\n",
    "    \n",
    "    # Calculate statistics for all variables\n",
    "    var_significance = {}\n",
    "    var_stats = {}\n",
    "    for var in valid_cols:\n",
    "        median_val = chinese_data.df_metadata[var].median()\n",
    "        stats, significant_hours = calculate_cgm_statistics(\n",
    "            chinese_data,\n",
    "            group1_filter=pl.col(var) > median_val\n",
    "        )\n",
    "        var_significance[var] = significant_hours\n",
    "        var_stats[var] = stats\n",
    "    \n",
    "    # Sort variables by significance\n",
    "    sorted_vars = sorted(var_significance.items(), key=lambda x: x[1], reverse=True)\n",
    "    ordered_vars = [v[0] for v in sorted_vars]\n",
    "    \n",
    "    # Create figure\n",
    "    n_vars = len(ordered_vars)\n",
    "    fig = plt.figure(figsize=(20, 6*n_vars))\n",
    "    gs = GridSpec(n_vars * 2, 1, figure=fig, height_ratios=[3, 1] * n_vars)\n",
    "    \n",
    "    # Plot variables in order of significance\n",
    "    for idx, var in enumerate(ordered_vars):\n",
    "        median_val = chinese_data.df_metadata[var].median()\n",
    "        stats = var_stats[var]\n",
    "        significant_hours = var_significance[var]\n",
    "        hours = np.arange(24)\n",
    "        \n",
    "        # Setup subplots\n",
    "        ax1 = fig.add_subplot(gs[2*idx])\n",
    "        ax2 = fig.add_subplot(gs[2*idx + 1])\n",
    "        \n",
    "        # Plot time series\n",
    "        if show_individual:\n",
    "            for curves, color in [(stats['group1_curves'], 'blue'), \n",
    "                                (stats['group2_curves'], 'red')]:\n",
    "                for patient_data in curves.values():\n",
    "                    ax1.plot(hours, patient_data, alpha=0.3, \n",
    "                            color=color, linewidth=1)\n",
    "        \n",
    "        # Calculate and plot means\n",
    "        for i, (curves, color, group_name) in enumerate([\n",
    "            (stats['group1_curves'], 'blue', f\"High {var}\"),\n",
    "            (stats['group2_curves'], 'red', f\"Low {var}\")\n",
    "        ]):\n",
    "            values = np.array(list(curves.values()))\n",
    "            mean = np.nanmean(values, axis=0)\n",
    "            sem = np.nanstd(values, axis=0) / np.sqrt(len(curves))\n",
    "            \n",
    "            ax1.plot(hours, mean, color=color, linewidth=2,\n",
    "                    label=f\"{group_name} (n={len(curves)})\")\n",
    "            ax1.fill_between(hours, mean - 1.96*sem, mean + 1.96*sem,\n",
    "                           color=color, alpha=0.2)\n",
    "        \n",
    "        # Plot significance\n",
    "        p_values = [stat['p_value'] for stat in stats['hourly_stats']]\n",
    "        significance = [1 - p for p in p_values]\n",
    "        ax2.plot(hours, significance, 'k-', linewidth=2)\n",
    "        ax2.axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='p=0.05')\n",
    "        ax2.fill_between(hours, 0.8, significance, alpha=0.2)\n",
    "        \n",
    "        # Style time series plot\n",
    "        ax1.set_xlim(0, 23)\n",
    "        ax1.set_ylim(100, 210)\n",
    "        ax1.set_xlabel('Hour of Day', labelpad=15)  # Added labelpad for more spacing\n",
    "        ax1.set_ylabel('CGM Value (mg/dL)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Add meal indicators\n",
    "        meal_times = [(6, 'Breakfast'), (12, 'Lunch'), (18, 'Dinner')]\n",
    "        for hour, meal in meal_times:\n",
    "            ax1.axvline(x=hour, color='gray', linestyle='--', alpha=0.3)\n",
    "            ax1.text(hour, ax1.get_ylim()[0], meal,\n",
    "                    rotation=90, va='top', ha='right')\n",
    "        \n",
    "        # Style p-value plot\n",
    "        ax2.set_xlim(0, 23)\n",
    "        ax2.set_ylim(0.8, 1)\n",
    "        ax2.set_xlabel('Hour of Day')\n",
    "        ax2.set_ylabel('Statistical Significance (1-p)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Set title with significance info\n",
    "        ratio = significant_hours / 24\n",
    "        title = f\"{var} (median split: {median_val:.2f})\\nSignificant hours: {significant_hours}/24 ({ratio:.1%})\"\n",
    "        ax1.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print sorted summary\n",
    "    print(\"\\nVariables ordered by significance:\")\n",
    "    for var in ordered_vars:\n",
    "        significant_hours = var_significance[var]\n",
    "        ratio = significant_hours / 24\n",
    "        print(f\"{var}: {significant_hours}/24 hours significant ({ratio:.1%})\")\n",
    "    \n",
    "    return ordered_vars, var_significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now observe temporal significance patterns when comparing high versus low\n",
    "clinical variable groups within the T2D population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_vars, var_significance = visualize_cgm_patterns_by_medians(chinese_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how metadata variables relate to each other by plotting a correlation heatmap, where variables are sorted by their CGM pattern significance. The diagonal will display the number of hours each variable shows statistically significant CGM differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sorted_correlations(\n",
    "    chinese_data: ChineseCGMData, \n",
    "    ordered_vars: list[str],  \n",
    "    significance_dict: dict[str, int]  \n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a correlation heatmap with variables sorted by their statistical significance.\n",
    "    Diagonal shows number of significant hours instead of self-correlation.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import polars as pl\n",
    "    \n",
    "    n_vars = len(ordered_vars)\n",
    "    \n",
    "    # Create two matrices: one for correlations, one for significant hours\n",
    "    corr_values = np.zeros((n_vars, n_vars))\n",
    "    sig_hours = np.zeros((n_vars, n_vars))\n",
    "    mask_sig = np.zeros((n_vars, n_vars), dtype=bool)\n",
    "    \n",
    "    # Fill matrices\n",
    "    for i, col1 in enumerate(ordered_vars):\n",
    "        for j, col2 in enumerate(ordered_vars):\n",
    "            if i == j:\n",
    "                sig_hours[i, j] = significance_dict[col1]\n",
    "                mask_sig[i, j] = True\n",
    "                corr_values[i, j] = 0  # This will be masked anyway\n",
    "            else:\n",
    "                corr = chinese_data.df_metadata.select(pl.corr(col1, col2)).item()\n",
    "                corr_values[i, j] = round(float(corr), 2) if corr is not None else np.nan\n",
    "    \n",
    "    # Create figure with extra space for labels\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Create simplified labels for x-axis (just variable names)\n",
    "    x_labels = [var.split('(')[0].strip() for var in ordered_vars]\n",
    "    # Keep full labels for y-axis\n",
    "    y_labels = [f\"{var} -\" for var in ordered_vars]\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    ax = sns.heatmap(corr_values,\n",
    "                     mask=mask_sig,  # Mask the diagonal\n",
    "                     annot=True,\n",
    "                     cmap='RdBu_r',\n",
    "                     center=0,\n",
    "                     vmin=-1,\n",
    "                     vmax=1,\n",
    "                     fmt='.2f',\n",
    "                     xticklabels=x_labels,\n",
    "                     yticklabels=y_labels,\n",
    "                     cbar_kws={\"shrink\": .8, \"label\": \"Correlation\"})\n",
    "    \n",
    "    # Plot significant hours on diagonal\n",
    "    # Use a different colormap and normalization for significance\n",
    "    sig_norm = plt.Normalize(0, 24)\n",
    "    sig_cmap = plt.cm.Reds\n",
    "    \n",
    "    for i in range(n_vars):\n",
    "        color = sig_cmap(sig_norm(sig_hours[i, i]))\n",
    "        ax.add_patch(plt.Rectangle((i, i), 1, 1, fill=True, color=color))\n",
    "        plt.text(i + 0.5, i + 0.5, f'{int(sig_hours[i, i])}',\n",
    "                ha='center', va='center', color='white' if sig_hours[i, i] > 12 else 'black')\n",
    "    \n",
    "    plt.title('Correlation Matrix (Variables Sorted by CGM Pattern Significance)\\nDiagonal shows significant hours', pad=20)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sorted_correlations(chinese_data, ordered_vars, var_significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will show how food events occur throughout the day by plotting their time distribution using both a density curve and raw counts. The visualization will highlight peak meal times and overall event frequency patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_time_distribution(events_df: pl.DataFrame, \n",
    "                               bin_width_minutes: int = 30,\n",
    "                               kde_bandwidth: float = 0.5,\n",
    "                               figsize: tuple = (12, 6)) -> None:\n",
    "    \"\"\"\n",
    "    Plot histogram and KDE of event times across the day with count on secondary axis.\n",
    "    \n",
    "    Args:\n",
    "        events_df: DataFrame from get_all_events_cgm_data\n",
    "        bin_width_minutes: Width of histogram bins in minutes\n",
    "        kde_bandwidth: Bandwidth parameter for kernel density estimation\n",
    "        figsize: Figure size as (width, height)\n",
    "    \"\"\"\n",
    "    # Extract hours as float (e.g., 14:30 -> 14.5)\n",
    "    event_times = []\n",
    "    for dt in events_df['event_date']:\n",
    "        hours = dt.hour\n",
    "        minutes = dt.minute\n",
    "        event_times.append(hours + minutes/60)\n",
    "    \n",
    "    total_events = len(event_times)\n",
    "    \n",
    "    # Create figure with two y-axes\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Calculate number of bins\n",
    "    bins = int(24 * 60 / bin_width_minutes)\n",
    "    \n",
    "    # Plot histogram with density on left axis\n",
    "    counts, bins, patches = ax1.hist(event_times, bins=bins, density=True, \n",
    "                                   alpha=0.6, color='skyblue', \n",
    "                                   label='Density')\n",
    "    \n",
    "    # Calculate and plot raw counts on right axis\n",
    "    counts_raw, _, patches_raw = ax2.hist(event_times, bins=bins, \n",
    "                                        alpha=0.0,  # Make invisible\n",
    "                                        label='Count')\n",
    "    \n",
    "    # Calculate KDE\n",
    "    kde = stats.gaussian_kde(event_times, bw_method=kde_bandwidth)\n",
    "    x_range = np.linspace(0, 24, 200)\n",
    "    ax1.plot(x_range, kde(x_range), 'r-', lw=2, \n",
    "            label='Kernel Density Estimate')\n",
    "    \n",
    "    # Customize plots\n",
    "    ax1.set_xlabel('Time of Day (hours)')\n",
    "    ax1.set_ylabel('Density', color='b')\n",
    "    ax2.set_ylabel('Count', color='g')\n",
    "    \n",
    "    plt.title(f'Distribution of Food Event Times (Total Events: {total_events:,})')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set x-axis ticks to show hours\n",
    "    ax1.set_xticks(np.arange(0, 25, 2))\n",
    "    \n",
    "    # Add hour labels\n",
    "    hours_labels = [f'{int(h):02d}:00' for h in np.arange(0, 25, 2)]\n",
    "    ax1.set_xticklabels(hours_labels)\n",
    "    \n",
    "    # Color the tick labels\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='g')\n",
    "    \n",
    "    # Add legends for both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + ['Count'], \n",
    "              loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_id = chinese_data.get_random_subject_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df = chinese_data.get_all_events_cgm_data(before_offset=\"-1h\",after_offset=\"3h\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event_time_distribution(data_df)\n",
    "single_subject_events_cgm_data = chinese_data.get_single_subject_events_cgm_data(random_id,before_offset=\"-1h\",after_offset=\"3h\")\n",
    "plot_event_time_distribution(single_subject_events_cgm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = chinese_data.get_all_events_cgm_data(before_offset=\"-12h\",after_offset=\"12h\")\n",
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-DRIVEN FOOD CATEGORIZATION FOR CGM EVENT ANALYSIS (Section 5)\n",
    "\n",
    "Note: here we're reading the results of the LLM food categorization from a parquet file, stored in `./LLM_outpts/processed_food_driary_entries.parquet`. To run the LLM food categorization, use the notebook `LLM_pipeline.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files saved with the LLM categorization\n",
    "loaded_df = pl.read_parquet(f\"{local_base_path}/processed_food_diary_entries.parquet\")\n",
    "loaded_df[\"should_reject_sample\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calories_df = loaded_df.filter(pl.col(\"should_reject_sample\") == False).select(pl.col(\"event_id\"),pl.col(\"meal_caloric_density\"))\n",
    "events_with_calories = events_df.join(calories_df,on=\"event_id\",how=\"left\").filter(pl.col(\"meal_caloric_density\").is_in([\"low\",\"average\"]))\n",
    "print(events_with_calories.shape)\n",
    "print(events_with_calories[\"meal_caloric_density\"].value_counts())\n",
    "events_with_calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import polars as pl\n",
    "from typing import Optional\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def calculate_hourly_p_values(group1_data, group2_data, standard_times):\n",
    "    \"\"\"\n",
    "    Calculate hourly p-values for two groups of CGM data aligned to event time.\n",
    "    \n",
    "    Args:\n",
    "        group1_data: List of (times, values) tuples for group 1\n",
    "        group2_data: List of (times, values) tuples for group 2\n",
    "        standard_times: Array of standardized time points\n",
    "    \n",
    "    Returns:\n",
    "        Array of p-values for each hour relative to the event\n",
    "    \"\"\"\n",
    "    hours = np.arange(int(standard_times[0] / 60), int(standard_times[-1] / 60) + 1)\n",
    "    p_values = []\n",
    "    \n",
    "    for hour in hours:\n",
    "        start_time = hour * 60\n",
    "        end_time = (hour + 1) * 60\n",
    "        \n",
    "        group1_values = []\n",
    "        group2_values = []\n",
    "        \n",
    "        for times, values in group1_data:\n",
    "            times = np.array(times)\n",
    "            values = np.array(values)\n",
    "            mask = (times >= start_time) & (times < end_time)\n",
    "            group1_values.extend(values[mask])\n",
    "        \n",
    "        for times, values in group2_data:\n",
    "            times = np.array(times)\n",
    "            values = np.array(values)\n",
    "            mask = (times >= start_time) & (times < end_time)\n",
    "            group2_values.extend(values[mask])\n",
    "        \n",
    "        if len(group1_values) > 0 and len(group2_values) > 0:\n",
    "            _, p_value = stats.ttest_ind(group1_values, group2_values)\n",
    "            p_values.append(p_value)\n",
    "        else:\n",
    "            p_values.append(np.nan)\n",
    "    \n",
    "    return np.array(p_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize CGM pattern comparisons between two patient groups split by clinical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aligned_cgm_events_by_group(\n",
    "    chinese_data: ChineseCGMData,\n",
    "    events_df: pl.DataFrame,\n",
    "    group1_filter: pl.Expr,\n",
    "    group2_filter: Optional[pl.Expr] = None,\n",
    "    group_names: tuple[str, str] = (\"Group 1\", \"Group 2\"),\n",
    "    show_individual: bool = False,\n",
    "    split_meals: bool = False,\n",
    "    split_by_calories: bool = True,\n",
    "    alpha_individual: float = 0.1,\n",
    "    figsize: tuple = (15, 10),\n",
    "    display: bool = True,\n",
    "    variable_name: str = \"Variable\"\n",
    ") -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    \"\"\"\n",
    "    Plot aligned CGM curves for events, split by clinical groups and caloric density.\n",
    "    Includes p-value plots for both between-group and within-group comparisons.\n",
    "    \"\"\"\n",
    "    # Get patient groups\n",
    "    group1_patients = chinese_data.df_metadata.filter(group1_filter)[\"Patient Number\"].to_list()\n",
    "    if group2_filter is None:\n",
    "        group2_patients = chinese_data.df_metadata.filter(~group1_filter)[\"Patient Number\"].to_list()\n",
    "    else:\n",
    "        group2_patients = chinese_data.df_metadata.filter(group2_filter)[\"Patient Number\"].to_list()\n",
    "    \n",
    "    # Adjust figure size for split view\n",
    "    if split_meals and split_by_calories:\n",
    "        figsize = (15, 25)  # Larger figure for all comparisons\n",
    "    \n",
    "    if split_meals:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        if split_by_calories:\n",
    "            fig = plt.figure(figsize=(15, 25))  # Increased height for additional plots\n",
    "            \n",
    "            # 10 rows: main title, legend space, between-group title, 3 CGM plots, 3 between-group p-value plots, \n",
    "            # within-group title, 3 within-group p-value plots\n",
    "            gs = GridSpec(10, 3, figure=fig, \n",
    "                        height_ratios=[0.2, 0.1, 0.2, 3, 3, 1, 1, 0.2, 1, 1])\n",
    "            \n",
    "            # Create title and section headers\n",
    "            title_ax = fig.add_subplot(gs[0, :])\n",
    "            between_groups_title_ax = fig.add_subplot(gs[2, :])  # Moved up before its plots\n",
    "            within_groups_title_ax = fig.add_subplot(gs[7, :])   # Moved up before its plots\n",
    "            title_ax.axis('off')\n",
    "            between_groups_title_ax.axis('off')\n",
    "            within_groups_title_ax.axis('off')\n",
    "            \n",
    "            # Create main plots\n",
    "            cgm_axes_low = [fig.add_subplot(gs[3, i]) for i in range(3)]\n",
    "            cgm_axes_avg = [fig.add_subplot(gs[4, i]) for i in range(3)]\n",
    "            \n",
    "            # Between-group p-value plots\n",
    "            p_axes_low = [fig.add_subplot(gs[5, i]) for i in range(3)]\n",
    "            p_axes_avg = [fig.add_subplot(gs[6, i]) for i in range(3)]\n",
    "            \n",
    "            # Within-group p-value plots\n",
    "            p_axes_within_group1 = [fig.add_subplot(gs[8, i]) for i in range(3)]\n",
    "            p_axes_within_group2 = [fig.add_subplot(gs[9, i]) for i in range(3)]\n",
    "            \n",
    "            cgm_axes = {'low': cgm_axes_low, 'average': cgm_axes_avg}\n",
    "            p_axes = {'low': p_axes_low, 'average': p_axes_avg}\n",
    "            p_axes_within = {group_names[0]: p_axes_within_group1, \n",
    "                            group_names[1]: p_axes_within_group2}\n",
    "\n",
    "   \n",
    "            within_groups_title_ax.text(0.5, 0.5, \n",
    "                \"Within-Group Comparisons (Low vs Average calories within each group and meal type)\", \n",
    "                ha='center', va='center', fontsize=10)\n",
    "        else:\n",
    "            gs = GridSpec(3, 3, figure=fig, height_ratios=[0.2, 3, 1])\n",
    "            title_ax = fig.add_subplot(gs[0, :])\n",
    "            title_ax.axis('off')\n",
    "            cgm_axes = [fig.add_subplot(gs[1, i]) for i in range(3)]\n",
    "            p_axes = [fig.add_subplot(gs[2, i]) for i in range(3)]\n",
    "            \n",
    "        meal_categories = ['Breakfast', 'Lunch', 'Dinner']\n",
    "    else:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = GridSpec(3, 1, figure=fig, height_ratios=[0.2, 3, 1])\n",
    "        title_ax = fig.add_subplot(gs[0])\n",
    "        title_ax.axis('off')\n",
    "        ax_cgm = fig.add_subplot(gs[1])\n",
    "        ax_p = fig.add_subplot(gs[2])\n",
    "        cgm_axes = [ax_cgm]\n",
    "        p_axes = [ax_p]\n",
    "        meal_categories = [None]\n",
    "\n",
    "    def wrap_title(text, width=40):\n",
    "        \"\"\"Wrap title text to multiple lines if too long\"\"\"\n",
    "        import textwrap\n",
    "        return '\\n'.join(textwrap.wrap(text, width=width))\n",
    "\n",
    "    # Create title with cutoff value\n",
    "    cutoff_value = chinese_data.df_metadata[variable_name].median()\n",
    "    n_group1 = len(group1_patients)\n",
    "    n_group2 = len(group2_patients)\n",
    "    title_text = wrap_title(\n",
    "        f'CGM Patterns by {variable_name}: High {variable_name} (>{cutoff_value:.1f}, n={n_group1}) vs '\n",
    "        f'Low {variable_name} (≤{cutoff_value:.1f}, n={n_group2})'\n",
    "    )\n",
    "    \n",
    "    title_ax.text(0.5, 0.5, title_text, ha='center', va='center', fontsize=12)\n",
    "\n",
    "\n",
    "    # Prepare data structures\n",
    "    caloric_densities = ['low', 'average'] if split_by_calories else [None]\n",
    "    groups_data = {\n",
    "        cal_dens: {\n",
    "            group_name: {meal: [] for meal in meal_categories}\n",
    "            for group_name in group_names\n",
    "        }\n",
    "        for cal_dens in caloric_densities\n",
    "    }\n",
    "    \n",
    "    groups_statistics = {\n",
    "        cal_dens: {\n",
    "            group: {meal: {'means': [], 'medians': [], 'sds': []} \n",
    "                   for meal in meal_categories}\n",
    "            for group in group_names\n",
    "        }\n",
    "        for cal_dens in caloric_densities\n",
    "    }\n",
    "        # Track global ranges\n",
    "    global_time_min = float('inf')\n",
    "    global_time_max = float('-inf')\n",
    "    \n",
    "    # First pass: determine global time range\n",
    "    for row in events_df.iter_rows(named=True):\n",
    "        cgm_values = row['CGM']\n",
    "        is_before = row['is_before_food_event']\n",
    "        onset_idx = np.where(np.array(is_before) == False)[0][0]\n",
    "        timestamps = [(i - onset_idx) * 15 for i in range(len(cgm_values))]\n",
    "        \n",
    "        global_time_min = min(global_time_min, min(timestamps))\n",
    "        global_time_max = max(global_time_max, max(timestamps))\n",
    "    \n",
    "    # Create standard time points\n",
    "    standard_times = np.arange(global_time_min, global_time_max + 15, 15)\n",
    "    \n",
    "    # Second pass: sort events into groups\n",
    "    for row in events_df.iter_rows(named=True):\n",
    "        patient = row['Patient Number']\n",
    "        current_category = row['event_type'] if split_meals else None\n",
    "        caloric_density = row.get('meal_caloric_density', None)\n",
    "        \n",
    "        if split_by_calories and caloric_density not in ['low', 'average']:\n",
    "            continue\n",
    "            \n",
    "        if patient in group1_patients:\n",
    "            group = group_names[0]\n",
    "        elif patient in group2_patients:\n",
    "            group = group_names[1]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        cgm_values = row['CGM']\n",
    "        is_before = row['is_before_food_event']\n",
    "        onset_idx = np.where(np.array(is_before) == False)[0][0]\n",
    "        timestamps = [(i - onset_idx) * 15 for i in range(len(cgm_values))]\n",
    "        \n",
    "        cal_dens = caloric_density if split_by_calories else None\n",
    "        groups_data[cal_dens][group][current_category].append((timestamps, cgm_values))\n",
    "    \n",
    "    # Calculate statistics and determine global CGM range\n",
    "    global_cgm_min = float('inf')\n",
    "    global_cgm_max = float('-inf')\n",
    "    \n",
    "    for cal_dens in caloric_densities:\n",
    "        for group in group_names:\n",
    "            for meal_category in meal_categories:\n",
    "                all_series = groups_data[cal_dens][group][meal_category]\n",
    "                if not all_series:\n",
    "                    continue\n",
    "                \n",
    "                values_matrix = np.full((len(all_series), len(standard_times)), np.nan)\n",
    "                \n",
    "                for idx, (times, values) in enumerate(all_series):\n",
    "                    interp_values = np.interp(standard_times, times, values)\n",
    "                    values_matrix[idx] = interp_values\n",
    "                \n",
    "                mean_curve = np.nanmean(values_matrix, axis=0)\n",
    "                median_curve = np.nanmedian(values_matrix, axis=0)\n",
    "                std_curve = np.nanstd(values_matrix, axis=0)\n",
    "                \n",
    "                groups_statistics[cal_dens][group][meal_category]['means'] = mean_curve\n",
    "                groups_statistics[cal_dens][group][meal_category]['medians'] = median_curve\n",
    "                groups_statistics[cal_dens][group][meal_category]['sds'] = std_curve\n",
    "                \n",
    "                if show_individual:\n",
    "                    global_cgm_min = min(global_cgm_min, np.nanmin(values_matrix))\n",
    "                    global_cgm_max = max(global_cgm_max, np.nanmax(values_matrix))\n",
    "                else:\n",
    "                    global_cgm_min = min(global_cgm_min, np.nanmin(mean_curve - std_curve))\n",
    "                    global_cgm_max = max(global_cgm_max, np.nanmax(mean_curve + std_curve))\n",
    "    \n",
    "    # Add padding to CGM range\n",
    "    cgm_range = global_cgm_max - global_cgm_min\n",
    "    global_cgm_min -= cgm_range * 0.05\n",
    "    global_cgm_max += cgm_range * 0.05\n",
    "    \n",
    "    # Colors for groups\n",
    "    colors = {group_names[0]: 'blue', group_names[1]: 'red'}\n",
    "    \n",
    "    # Plot each caloric density category\n",
    "    for cal_dens in caloric_densities:\n",
    "        current_cgm_axes = cgm_axes[cal_dens] if split_by_calories and split_meals else cgm_axes\n",
    "        current_p_axes = p_axes[cal_dens] if split_by_calories and split_meals else p_axes\n",
    "        \n",
    "        for ax_idx, (ax_cgm, ax_p, meal_category) in enumerate(zip(current_cgm_axes, current_p_axes, meal_categories)):\n",
    "            group1_data = groups_data[cal_dens][group_names[0]][meal_category]\n",
    "            group2_data = groups_data[cal_dens][group_names[1]][meal_category]\n",
    "            \n",
    "            # Get event counts for title\n",
    "            group1_count = len(group1_data)\n",
    "            group2_count = len(group2_data)\n",
    "            total_events = group1_count + group2_count\n",
    "            \n",
    "            for group in group_names:\n",
    "                all_series = groups_data[cal_dens][group][meal_category]\n",
    "                if not all_series:\n",
    "                    continue\n",
    "                \n",
    "                color = colors[group]\n",
    "                \n",
    "                if show_individual:\n",
    "                    for times, values in all_series:\n",
    "                        interp_values = np.interp(standard_times, times, values)\n",
    "                        ax_cgm.plot(standard_times, interp_values, '-', \n",
    "                                  color=color, alpha=alpha_individual)\n",
    "                \n",
    "                stats = groups_statistics[cal_dens][group][meal_category]\n",
    "                mean_curve = stats['means']\n",
    "                std_curve = stats['sds']\n",
    "                \n",
    "                ax_cgm.plot(standard_times, mean_curve, '-', \n",
    "                           color=color, linewidth=2, \n",
    "                           label=f'{group} (n={len(all_series)})')\n",
    "                ax_cgm.fill_between(standard_times, \n",
    "                                  mean_curve - std_curve, \n",
    "                                  mean_curve + std_curve,\n",
    "                                  color=color, alpha=0.2)\n",
    "            \n",
    "            # Plot between-group p-values\n",
    "            if group1_data and group2_data:\n",
    "                p_values = calculate_hourly_p_values(group1_data, group2_data, standard_times)\n",
    "                hours = np.arange(int(standard_times[0] / 60), int(standard_times[-1] / 60) + 1)\n",
    "                \n",
    "                significance = 1 - p_values\n",
    "                \n",
    "                ax_p.plot(hours * 60, significance, 'k-', linewidth=2, label='Significance')\n",
    "                ax_p.axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='p=0.05')\n",
    "                ax_p.fill_between(hours * 60, 0, significance, alpha=0.2)\n",
    "                \n",
    "                ax_p.set_ylim(0.8, 1)\n",
    "                ax_p.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Common plot elements\n",
    "            ax_cgm.axvline(x=0, color='k', linestyle='--', label='Event Onset')\n",
    "            ax_cgm.set_ylim(global_cgm_min, global_cgm_max)\n",
    "            ax_cgm.set_xlim(standard_times[0], standard_times[-1])\n",
    "            \n",
    "            for ax in [ax_cgm, ax_p]:\n",
    "                ax.set_xlabel('Minutes from Event')\n",
    "                xticks = np.arange(standard_times[0], standard_times[-1] + 1, 120)\n",
    "                ax.set_xticks(xticks)\n",
    "                ax.set_xticklabels([str(int(x)) for x in xticks])\n",
    "            \n",
    "            if ax_idx == 0:\n",
    "                ax_cgm.set_ylabel('CGM Value')\n",
    "                ax_p.set_ylabel('Statistical Significance (1-p)')\n",
    "            \n",
    "            # Create title with event counts\n",
    "            if meal_category:\n",
    "                cal_dens_text = f\" ({cal_dens.capitalize()} Calories)\" if cal_dens else \"\"\n",
    "                title = wrap_title(\n",
    "                    f'{meal_category} Events{cal_dens_text} High: {group1_count}, Low: {group2_count}'\n",
    "                )\n",
    "            else:\n",
    "                title = wrap_title(\n",
    "                    f'All Events High: {group1_count}, Low: {group2_count}'\n",
    "                )\n",
    "            \n",
    "            ax_cgm.set_title(title)\n",
    "            ax_cgm.grid(True, alpha=0.3)\n",
    "            ax_p.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add within-group p-value plots if using split view\n",
    "    if split_by_calories and split_meals:\n",
    "        for group in group_names:\n",
    "            for ax_idx, (ax_p, meal_category) in enumerate(zip(p_axes_within[group], meal_categories)):\n",
    "                low_cal_data = groups_data['low'][group][meal_category]\n",
    "                avg_cal_data = groups_data['average'][group][meal_category]\n",
    "                \n",
    "                if low_cal_data and avg_cal_data:\n",
    "                    p_values = calculate_hourly_p_values(low_cal_data, avg_cal_data, standard_times)\n",
    "                    hours = np.arange(int(standard_times[0] / 60), int(standard_times[-1] / 60) + 1)\n",
    "                    \n",
    "                    significance = 1 - p_values\n",
    "                    \n",
    "                    ax_p.plot(hours * 60, significance, 'k-', linewidth=2)\n",
    "                    ax_p.axhline(y=0.95, color='r', linestyle='--', alpha=0.5)\n",
    "                    ax_p.fill_between(hours * 60, 0, significance, alpha=0.2)\n",
    "                    \n",
    "                    ax_p.set_ylim(0.8, 1)\n",
    "                    ax_p.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    if ax_idx == 0:\n",
    "                        ax_p.set_ylabel(f'{group}\\nSignificance (1-p)')\n",
    "                    ax_p.set_xlabel('Minutes from Event')\n",
    "                    \n",
    "                    # Add title with sample sizes\n",
    "                    n_low = len(low_cal_data)\n",
    "                    n_avg = len(avg_cal_data)\n",
    "                    ax_p.set_title(f'{meal_category}\\n(Low: {n_low}, Avg: {n_avg})')\n",
    "                else:\n",
    "                    print(f\"Skipping within-group p-value calculation for {group}, {meal_category}\")\n",
    "\n",
    "    # Create a single legend\n",
    "    handles, labels = (cgm_axes['low'] if split_by_calories and split_meals else cgm_axes)[0].get_legend_handles_labels()\n",
    "    p_handles, p_labels = (p_axes['low'] if split_by_calories and split_meals else p_axes)[0].get_legend_handles_labels()\n",
    "    \n",
    "    unique_labels = []\n",
    "    unique_handles = []\n",
    "    for handle, label in zip(handles + p_handles, labels + p_labels):\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "            unique_handles.append(handle)\n",
    "    \n",
    "    # Move legend between title and plots\n",
    "    if split_by_calories and split_meals:\n",
    "        legend_y = 0.88\n",
    "    else:\n",
    "        legend_y = 0.85\n",
    "    \n",
    "    fig.legend(unique_handles, unique_labels, \n",
    "              loc='upper center', bbox_to_anchor=(0.5, legend_y), ncol=5)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    if split_by_calories and split_meals:\n",
    "        plt.subplots_adjust(top=0.92, bottom=0.05, hspace=0.6)\n",
    "    else:\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with groups based on some clinical variable\n",
    "fig = plot_aligned_cgm_events_by_group(\n",
    "    chinese_data,\n",
    "    events_with_calories,\n",
    "    group1_filter=pl.col(\"HbA1c (mmol/mol)\") > chinese_data.df_metadata[\"HbA1c (mmol/mol)\"].median(),\n",
    "    group_names=(\"High HbA1c\", \"Low HbA1c\"),\n",
    "    split_meals=True,\n",
    "    variable_name=\"HbA1c (mmol/mol)\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ordered_vars:\n",
    "    plot_aligned_cgm_events_by_group(\n",
    "    chinese_data,\n",
    "    events_with_calories,\n",
    "    group1_filter=pl.col(column) > chinese_data.df_metadata[column].median(),\n",
    "    group_names=(f\"High {column}\", f\"Low {column}\"),\n",
    "    split_meals=True,\n",
    "    variable_name=column,\n",
    "    split_by_calories=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
